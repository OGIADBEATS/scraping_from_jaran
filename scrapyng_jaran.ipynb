from google.colab import drive
drive.mount('./gdrive')

!pip install selenium

from bs4 import BeautifulSoup
import requests
import urllib.robotparser
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
import time

############################################

#-----スクレイピング-----#

ranking_url = "https://www.jalan.net/jalan/doc/ranking/total/03_index.html"

#スクレイピング可能か調べる
robots_url = "https://www.jalan.net/robots.txt"

rp = urllib.robotparser.RobotFileParser()
rp.set_url(robots_url)
rp.read()

user_agent = '*'
result = rp.can_fetch(user_agent, ranking_url)
print(result)
