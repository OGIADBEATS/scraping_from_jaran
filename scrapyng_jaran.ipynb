from google.colab import drive
drive.mount('./gdrive')

!pip install selenium

from bs4 import BeautifulSoup
import requests
import urllib.robotparser
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
import time

############################################

#-----スクレイピング-----#

ranking_url = "https://www.jalan.net/jalan/doc/ranking/total/03_index.html"

#スクレイピング可能か調べる
robots_url = "https://www.jalan.net/robots.txt"

rp = urllib.robotparser.RobotFileParser()
rp.set_url(robots_url)
rp.read()

user_agent = '*'
result = rp.can_fetch(user_agent, ranking_url)
print(result)

#-----クローリング-----#

#ブラウザをheadlessモード実行
options = webdriver.ChromeOptions()
#ヘッドレスモード（バックグラウンドで起動）で実行。コラボの場合、必須。
options.add_argument('--headless')
#サンドボックスモードの解除。これも必須。
options.add_argument('--no-sandbox')
#これも設定した方がよい。
options.add_argument('--disable-dev-shm-usage')
#おまじない
driver = webdriver.Chrome(options=options)
driver.implicitly_wait(10)
